---
title: "Qualtrics LLM Panel Preregistration"
author: "Colin Maggard, Claire Punturieri, John Curtin"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
format:
  html:
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

## Purpose of Preregistration

The purpose of this document is to **preregister analyses for evaluating individual differences in message helpfulness ratings across different tones and styles**. This preregistration was completed prior to data collection with the intent of removing researcher degrees of freedom from our analyses.

## Study Overview
 
These data will be collected using a Qualtrics panel study. Five hundred individuals who score above 8 on the Alcohol Use Disorder Identification Test (AUDIT) Self-Report (suggestive of hazardous or harmful use) will complete three surveys. The first survey will collect demographic characteristics (e.g., age, sex, race, income). The second survey will present participants with a set of linguistic tones (6) and styles (2) designed to be applied to supportive messages generated with the use of large language models (LLMs). In this survey, participants will provide ratings of how helpful they believe each of these message tones and styles would be if used in the context of a recovery monitoring and support system that provides daily supportive messages on a 7-point Likert scale. In the third and final survey, participants will be provided with 48 specific, supportive messages generated by an LLM written in all possible combinations of tone and style (four exemplars of each) and will be asked to rate each message's helpfulness on a 7-point Likert scale. Four sets of surveys will be distributed which consist of the *same* tone and style combinations for messages, but display messages with different text; each participant will only see one survey.

We have two primary aims:
1. Across the 48 messages, do demographic characteristics (e.g., sex at birth, race) predict individuals' ratings of message helpfulness above and beyond the message tone and style?
2. When controlling for demographic characteristics, do initial helpfulness ratings of tone and style further improve our predictions of what message tone and style an individual will find most helpful? In other words, are individuals able to accurately assess the tone and style they believe to be most helpful and does this better enable us to predict which message tone/style combination an individual should be assigned to?

The results of the analyses of these aims will guide us in determining if we should use 1) the same tones and styles for everyone (i.e., the most preferred tone and style across all individuals is assigned to each participant); 2) match tones and styles for each individual to their demographic characteristics (e.g., if women, on average, prefer a particular tone/style, that tone/style will be assigned to all women); or 3) select tones and styles for each participant based on their own reports of what tone and style they perceive as most helpful. Ultimately, we hope to optimize messages in a recovery monitoring and support system such that they are maximally helpful for all participants.

## Analysis plan

### Overview

Broadly, we will train, evaluate, and sequentially compare three machine learning models designed to predict participants' helpfulness ratings of the 48 messages generated by a LLM (i.e., ratings of message helpfulness is our primary outcome).

The first model ("baseline" model) will predict message helpfulness ratings based only on the tone and style of each message. The second model ("demographics" model) will predict message helpfulness using tone, style, and features representing participants' demographic characteristics. The third model ("preferences" model) will predict message helpfulness using tone, style, demographic characteristics, and features derived from initial ratings of tone and style helpfulness.

The first aim will be assessed by comparing the performance of the demographics model against the baseline model. The second aim will be assessed by comparing the performance of the preferences model against the demographics model.

### Model Selection and Evaluation

Our primary performance metric for model selection and evaluation for each of the three models (baseline, demographics, and preferences) will be mean absolute error (MAE).

Two commonly used tree-based algorithms will be considered: XGBoost and Random Forest. Tree-based models allow for the modeling of complex, non-linear, and/or interactive relationships natively. Moreover, these algorithms are well-suited to address issues of bias-variance trade-off in performance. All model configurations will vary across appropriate values for key hyperparameters.

Participant-grouped, nested k-fold cross-validation will be used for model training, selection, and evaluation for each of the three models. Model selection will be carried out using the inner loop of 1 repeat of 10-fold CV (10 validation sets). Model evaluation will be carried out using the outer loop of 3 repeats of 10-fold CV (30 test sets).

### Model Comparisons

We will perform two Bayesian model comparisons which compare an augmented and compact model, where the augmented model includes the compact model plus additional features. Specifically, we will first compare the baseline and the demographics model (i.e., can we increase the accuracy of our predictions of individual message helpfulness, beyond message characteristics, by including demographic information?; baseline vs demographics). Second, we will compare the demographics model and the preferences model (i.e., can we increase the accuracy of our predictions of individual message helpfulness, beyond demographics, by including individual ratings of what tone and style they perceive as most helpful?; demographics vs preferences).

For each comparison, the inputs are the 30 test set MAEs for the two relevant models. These analyses will be conducted following guidelines from *tidymodels* (Kuhn & Wickham, 2020) using the *tidyposterior* package (Kuhn, 2022). These Bayesians models will have two random intercepts for the repeat and fold within repeats, weakly informative priors, and follow other guidelines from *tidyposterior* (Kuhn, 2022) and *rstanarm* developers (Goodrich, Garby, Ali & Brilleman, 2025). We will report the probability that the augmented model performance exceeds the performance of the compact model (e.g., demographics model better than baseline) and a 95% Bayesian CI on the magnitude of that performance difference.

### Feature Importance

We intend to report feature importance for the best performing model. We will use global SHAP values to index feature importance in this best model.

### References

Goodrich, B., Gabry, J., Ali, I., Brilleman, S. (2025). rstanarm: Bayesian applied regression modeling via Stan. https://mc-stan.org/rstanarm/. 

Kuhn, M. (2022). Tidyposterior: Bayesian analysis to compare models using resampling statistics. https://cran.r-project.org/web/packages/tidyposterior/index.html

Kuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org


