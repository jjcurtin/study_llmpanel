---
title: "Qualtrics LLM Panel Preregistration"
author: "Colin Maggard and Claire Punturieri"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
format:
  html:
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# To do

Claire:
 - Write out models
 - Email Markus to ask about model/set up meeting --> will email Ben, Markus OOO

Colin:
  - Generating the data
  - Start outlining the study overview section

```{r}
library(stats)
library(lme4)
library(tidyverse) 
library(psych) 
library(car)
library(performance) # for icc
```

# Study Overview

## Specific Aims

## Data

# Purpose of Preregistration

## Outcomes

## Focal and Secondary Effects

# Data Generation

Simulated data should have:

 1. We should see clear differences in actual ratings of messages. Within each tone/style, people's ratings should be pretty similar to one another (low variance) but between tone/style ratings should be noticeably different (high variance).
 
 Example: people might rate the norms tone at around a 6/7 but the self-efficacy tone at around a 3/7.

 2. Stated preferences should match actual ratings.
 
 Example: if someone says they like "informal" messages, then their ratings of actual "informal" messages should be high, too.

 3. We want to observe a demographic difference. Create a sex variable (male/female) where there is a clear difference in tone/style preferences.
 
 Example: prefer "norms" messages and women prefer "legitimizing" messages.

 4. We want tone and style to interact.
 
 Example: all tones that are crossed with the "informal" style to have higher actual ratings than all tones crossed with the "formal" style.

Some other notes for making it realistic!

 - Make sure there's a little bit of randomness (we don't want two given person's ratings to be identical, but we still want the patterns above to be obvious)
 - Make sure that not every person's stated preference perfectly matches their actual message ratings
 - Keep ratings in the real range of values we'll be collecting (e.g., 1-7 Likert scale)

# Preregistered Analyses

Variables:
 - sub_id
 - pref_rating (how much would you like to receive a message in this style/tone)
 - pref_rating_style
 - pref_rating_tone
 - actual_rating (how helpful do you find this message)
 - style (informal, formal)
 - tone (value affirmation, norms, acknowledging, self-efficacy, caring/supportive, legitimizing)
 - context (high/increasing, low/increasing, high/decreasing, low/decreasing)
 - age
 - sex
 - gender_id
 - sexual_orientation
 - race_ethn
 - education
 - income
 - marital_status
 - no_in_household
 - minoritized
 - income_adj (will be calculated as: income / no_in_household)
 
## Models 1 & 2 - Style and tone stated preferences

Answers:

 - Do people have message tone and/or style preferences? (stated preferences from categories)
 - Are there demographic differences in these preferences? (demonstrated here using sex variable)
 
By testing:

 - The main effects of style and tone separately
 - The main effect of sex
 - The interaction between sex and style/tone

For style:
```{r}
m1 <- lm(pref_rating_style ~ style*sex, data = d)
```

For tone:
```{r}
m2 <- lm(pref_rating_tone ~ tone*sex, data = d)
```

## Model 3 - Style and tone actual ratings

Answers:

 - Do people have actual message tone and/or style differences?
 - Is there an interaction between tone and style?
 - Are there demographic differences in actual message ratings?
 
By testing:

 - The main effects of style and tone condition on actual ratings
 - The interactive effect of style and tone
 - The main effect of sex on actual ratings
 - While accounting for individual differences by including random intercepts for participants and messages
 - While modeling individual variability in effects of style and tone with random slopes by participant
 
> This would be the model where we could incorporate context if we are able to do the necessary randomization for that. Then I think we'd need random slope for context within participant.

```{r}
m3 <- lmer(actual_rating ~ style*tone + sex +
             (1 + style*tone | participant) + (1 | message),
           data = d)
```

Note to Claire to add in model simplification steps that will be carried out should model not converge.

## Model 4 - Concordance between preferences and actual ratings

Answers:

 - Do message tone and style preferences correspond to actual ratings?
 
By testing:

 - Main effects of style and tone preferences on actual ratings
 - While accounting for individual differences by including random intercepts for participants and messages
 - While modeling individual variability in effects of style and tone with random slopes by participant


```{r}
m4 <- lmer(actual_rating ~ pref_rating_tone + pref_rating_style +
             (1 + pref_rating_tone + pref_rating_style | participant) + (1 | message),
           data = d)
```

> Do we want demographic characteristics in here? Unsure. Also think about if pref_rating_tone and pref_rating_style should be an interaction. This might also be a good place to try out Spearman's ranked correlations.

## Models 5, 6, 7, & 8 - Within and between comparisons (ICC)

Answers:

 - Are participant ratings of their preferences more different across tone/style categories than within tone/style categories?
 - Are participant ratings of messages more different across tone/style categories than within tone/style categories?

For tone/style preferences:
```{r}
m5 <- lmer(pref_rating_tone ~ 1 + (1 | tone), data = d)
icc(m5)

m6 <- lmer(pref_rating_style ~ 1 + (1 | style), data = d)
icc(m6)
```

For tone/style actual ratings:
```{r}
m7 <- lmer(actual_rating ~ 1 + (1 | tone) + (1 | participant) + (1 | message), data = d)
icc(m7)

m8 <- lmer(actual_rating ~ 1 + (1 | style) + (1 | participant) + (1 | message), data = d)
icc(m8)
```

> ICC does not work with ranked ordered categories, but there is a rank ICC package we could consider using: https://pmc.ncbi.nlm.nih.gov/articles/PMC10592008/ https://github.com/shengxintu/rankICC This paper has only been cited 10 times so might not be the best option.

 
# Notes

 - Are pref_rating_style/tone and actual_rating comparable? Should pref be "helpful" instead of like?
 - Should pref_rating be one variable or separated into two?
 - Are we going to use context?
 - Note that gender_id is fill in the blank so probably can't use in analyses. Should this be specific categories?

 